{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BikeRecognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaiJsS3qMPDl",
        "colab_type": "text"
      },
      "source": [
        "#Jupyter notebook to train our model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG6SOKWUfnVb",
        "colab_type": "text"
      },
      "source": [
        "##Step 1: Installing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU9DlRZtLoBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/Mattveloso/Mask_RCNN.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1psPwR66S2Bc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wjFTOU3Ac9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!git clone https://github.com/philferriere/cocoapi.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JGyqUVhL7u2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUFGy2OGMAX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd Mask_RCNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHR0YEI6MG60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 setup.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5GTI86GMUYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==1.15.0\n",
        "!pip install gast==0.3.2\n",
        "!pip install keras==2.2.5\n",
        "!pip install -r requirements.txt\n",
        "!pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAE34T8bNWtJ",
        "colab_type": "text"
      },
      "source": [
        "##Step 2: Importing Libraries and Running\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W4sigfSNT9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# File for bicycle type Classification Main source is MachineLearningMastery.com\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#from pycocotools import *\n",
        "from samples.coco import coco\n",
        "from mrcnn import utils\n",
        "from mrcnn import model as modellib\n",
        "from mrcnn import visualize\n",
        "\n",
        "from os import listdir\n",
        "from xml.etree import ElementTree\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "from mrcnn.utils import Dataset\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.model import MaskRCNN\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "ROOT_DIR = os.getcwd()\n",
        "g_path = '/content/' #general path for files\n",
        "\n",
        "#directory to save logs\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "#get traned weights from google drive\n",
        "COCO_MODEL_PATH = '/content/drive/My Drive/Colab/mask_rcnn_coco.h5'\n",
        "#download weights if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "  utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "#Directory of images to run detection on\n",
        "IMAGE_DIR = g_path+'Mask_RCNN/bikes/images/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STieThWS_g2K",
        "colab_type": "text"
      },
      "source": [
        "###Config and Class names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ6twEQg_cH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InferenceConfig(coco.CocoConfig):\n",
        "  #set batch size to 1 since we'lll be running inference on one image at a time. Batch size = GPU_COUNT*IMAGES_PER_GPU\n",
        "  GPU_COUNT=1\n",
        "  IMAGES_PER_GPU=1 #i want to change to 1\n",
        "  NUM_CLASSES=5\n",
        "\n",
        "config = InferenceConfig()\n",
        "config.display()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cguXwJdJPmfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names=['BG', 'RoadBike', 'KidsBike','MountainBike','UrbanBike']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp7I0_8t_cjy",
        "colab_type": "text"
      },
      "source": [
        "###MachineLearningMastery based code below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk8sq3CsNwE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %% class that defines and loads the Roadbike dataset\n",
        "class BikesDataset(Dataset):\n",
        "\t# load the dataset definitions\n",
        "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
        "\t\t# define classes\n",
        "\t\tself.add_class('dataset', 1, \"RoadBike\")\n",
        "\t\tself.add_class('dataset', 2, \"KidsBike\")\n",
        "\t\tself.add_class('dataset', 3, \"MountainBike\")\n",
        "\t\tself.add_class('dataset', 4, \"UrbanBike\")\n",
        "\t\t# define data locations\n",
        "\t\timages_dir = dataset_dir + '/images/'\n",
        "\t\tannotations_dir = dataset_dir + '/annots/'\n",
        "\t\t# find all images\n",
        "\t\t\n",
        "\t\tfor filename in RoadBikes_image_list:\n",
        "\t\t\t# extract image id\n",
        "\t\t\timage_id = filename[:-4]\n",
        "\t\t\t# skip all images after 150 if we are building the train set\n",
        "\t\t\tif is_train and float(image_id) >= 125:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t# skip all images before 150 if we are building the test/val set\n",
        "\t\t\tif not is_train and float(image_id) < 125:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\timg_path = images_dir + filename\n",
        "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
        "\t\t\t# add to dataset\n",
        "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path,num_ids=1)\n",
        "\n",
        "\t\tfor filename in KidsBikes_image_list:\n",
        "\t\t\t# extract image id\n",
        "\t\t\timage_id = filename[:-4]\n",
        "\t\t\t# skip all images after 150 if we are building the train set\n",
        "\t\t\tif is_train and float(image_id) >= 250:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t# skip all images before 150 if we are building the test/val set\n",
        "\t\t\tif not is_train and float(image_id) < 250:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\timg_path = images_dir + filename\n",
        "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
        "\t\t\t# add to dataset\n",
        "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path,num_ids=2)\n",
        "\n",
        "\t\t#mountain bikes go from 97 to 144 , list= MTB_image_list\n",
        "\t\tfor filename in MTB_image_list:\n",
        "\t\t\t# extract image id\n",
        "\t\t\timage_id = filename[:-4]\n",
        "\t\t\t# skip all images after 150 if we are building the train set\n",
        "\t\t\tif is_train and float(image_id) >= 400:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t# skip all images before 150 if we are building the test/val set\n",
        "\t\t\tif not is_train and float(image_id) < 400:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\timg_path = images_dir + filename\n",
        "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
        "\t\t\t# add to dataset\n",
        "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path,num_ids=3)\n",
        "\t \n",
        "\t\t#Urban bikes go from 145 to 173, list = UrbanBikes_image_list\n",
        "\t\tfor filename in UrbanBikes_image_list:\n",
        "\t\t\t# extract image id\n",
        "\t\t\timage_id = filename[:-4]\n",
        "\t\t\t# skip all images after 150 if we are building the train set\n",
        "\t\t\tif is_train and float(image_id) >= 510:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t# skip all images before 150 if we are building the test/val set\n",
        "\t\t\tif not is_train and float(image_id) < 510:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\timg_path = images_dir + filename\n",
        "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
        "\t\t\t# add to dataset\n",
        "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path,num_ids=4)\n",
        "\n",
        "\t# extract bounding boxes from an annotation file\n",
        "\tdef extract_boxes(self, filename):\n",
        "\t\t# load and parse the file\n",
        "\t\ttree = ElementTree.parse(filename)\n",
        "\t\t# get the root of the document\n",
        "\t\troot = tree.getroot()\n",
        "\t\t# extract each bounding box\n",
        "\t\tboxes = list()\n",
        "\t\tfor box in root.findall('.//bndbox'):\n",
        "\t\t\txmin = int(box.find('xmin').text)\n",
        "\t\t\tymin = int(box.find('ymin').text)\n",
        "\t\t\txmax = int(box.find('xmax').text)\n",
        "\t\t\tymax = int(box.find('ymax').text)\n",
        "\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
        "\t\t\tboxes.append(coors)\n",
        "\t\t# extract image dimensions\n",
        "\t\twidth = int(root.find('.//size/width').text)\n",
        "\t\theight = int(root.find('.//size/height').text)\n",
        "\t\treturn boxes, width, height, filename\n",
        "\n",
        "\t# load the masks for an image\n",
        "\tdef load_mask(self, image_id):\n",
        "\t\t# get details of image\n",
        "\t\tinfo = self.image_info[image_id]\n",
        "\t\t# define box file location\n",
        "\t\tpath = info['annotation']\n",
        "\t\t# load XML\n",
        "\t\tboxes, w, h, filename = self.extract_boxes(path)\n",
        "\t\t# create one array for all masks, each on a different channel\n",
        "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
        "\t\t# create masks\n",
        "\t\tclass_ids = list()\n",
        "\t\tfor i in range(len(boxes)):\n",
        "\t\t\tbox = boxes[i]\n",
        "\t\t\trow_s, row_e = box[1], box[3]\n",
        "\t\t\tcol_s, col_e = box[0], box[2]\n",
        "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
        "\t\t\tID = filename.split('/')\n",
        "\t\t\tif int(ID[-1][:-4]) <= 160:\n",
        "\t\t\t\tclass_ids.append(self.class_names.index('RoadBike'))\n",
        "\t\t\telif (int(ID[-1][:-4]) > 160) and  (int(ID[-1][:-4]) < 279) :\n",
        "\t\t\t\tclass_ids.append(self.class_names.index('KidsBike'))\n",
        "\t\t\telif (int(ID[-1][:-4]) >= 279) and  (int(ID[-1][:-4]) < 439) :\n",
        "\t\t\t\tclass_ids.append(self.class_names.index('MountainBike'))\n",
        "\t\t\telif (int(ID[-1][:-4]) >= 439) and  (int(ID[-1][:-4]) <= 524) :\n",
        "\t\t\t\tclass_ids.append(self.class_names.index('UrbanBike'))\t\t\n",
        "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
        "\n",
        "\t# load an image reference\n",
        "\tdef image_reference(self, image_id):\n",
        "\t\tinfo = self.image_info[image_id]\n",
        "\t\treturn info['path']\n",
        "\n",
        "# define a configuration for the model\n",
        "class BikesConfig(Config):\n",
        "\t# define the name of the configuration\n",
        "\tNAME = \"Bikes_Cfg\"\n",
        "\tGPU_COUNT = 1\n",
        "\tIMAGES_PER_GPU = 1\n",
        "\t# number of classes (background + bikes) \n",
        "\tNUM_CLASSES = 5\n",
        "\t# number of training steps per epoch\n",
        "\tSTEPS_PER_EPOCH = 132"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsGjuGpiXW-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir\n",
        "from xml.etree import ElementTree\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "from numpy import expand_dims\n",
        "from numpy import mean\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.model import MaskRCNN\n",
        "from mrcnn.utils import Dataset\n",
        "from mrcnn.utils import compute_ap\n",
        "from mrcnn.model import load_image_gt\n",
        "from mrcnn.model import mold_image\n",
        "\n",
        "# define the prediction configuration\n",
        "class PredictionConfig(Config):\n",
        "\t# define the name of the configuration\n",
        "\tNAME = \"Bikes_Cfg\"\n",
        "\t# number of classes (background + kangaroo)\n",
        "\tNUM_CLASSES = 1 + 4\n",
        "\t# simplify GPU config\n",
        "\tGPU_COUNT = 1\n",
        "\tIMAGES_PER_GPU = 1\n",
        "\n",
        "# plot a number of photos with ground truth and predictions\n",
        "def plot_actual_vs_predicted(dataset, model, cfg, n_images=20):\n",
        "\t# load image and mask\n",
        "\tfor i in range(n_images):\n",
        "\t\t# load the image and mask\n",
        "\t\timage = dataset.load_image(i)\n",
        "\t\tmask, _ = dataset.load_mask(i)\n",
        "\t\t#classe = dataset.load_class(i)\n",
        "\t\t#print(classe)\n",
        "\t\t# convert pixel values (e.g. center)\n",
        "\t\tscaled_image = mold_image(image, cfg)\n",
        "\t\t# convert image into one sample\n",
        "\t\tsample = expand_dims(scaled_image, 0)\n",
        "\t\t# make prediction\n",
        "\t\tyhat = model.detect(sample, verbose=0)[0]\n",
        "\t\t# define subplot\n",
        "\t\tpyplot.subplot(n_images, 2, i*2+1)\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(image)\n",
        "\t\tpyplot.title('Actual')\n",
        "\t\t# plot masks\n",
        "\t\tfor j in range(mask.shape[2]):\n",
        "\t\t\tpyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
        "\t\t# get the context for drawing boxes\n",
        "\t\tpyplot.subplot(n_images, 2, i*2+2)\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(image)\n",
        "\t\tpyplot.title('Predicted')\n",
        "\t\tax = pyplot.gca()\n",
        "\t\t# plot each box\n",
        "\t\tfor box in yhat['rois']:\n",
        "\t\t\t# get coordinates\n",
        "\t\t\ty1, x1, y2, x2 = box\n",
        "\t\t\t# calculate width and height of the box\n",
        "\t\t\twidth, height = x2 - x1, y2 - y1\n",
        "\t\t\t# create the shape\n",
        "\t\t\trect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
        "\t\t\t# draw the box\n",
        "\t\t\tax.add_patch(rect)\n",
        "\t# show the figure\n",
        "\tpyplot.show()\n",
        "\n",
        "# calculate the mAP for a model on a given dataset\n",
        "def evaluate_model(dataset, model, cfg):\n",
        "\tAPs = list()\n",
        "\tfor image_id in dataset.image_ids:\n",
        "\t\t# load image, bounding boxes and masks for the image id\n",
        "\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
        "\t\t# convert pixel values (e.g. center)\n",
        "\t\tscaled_image = mold_image(image, cfg)\n",
        "\t\t# convert image into one sample\n",
        "\t\tsample = expand_dims(scaled_image, 0)\n",
        "\t\t# make prediction\n",
        "\t\tyhat = model.detect(sample, verbose=0)\n",
        "\t\t# extract results for first sample\n",
        "\t\tr = yhat[0]\n",
        "\t\t# calculate statistics, including AP\n",
        "\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "\t\tprint('Real: '+ gt_class_id +' | Predicted: '+ r['class_ids'])\n",
        "\t\t# store\n",
        "\t\tAPs.append(AP)\n",
        "\t# calculate the mean AP across all images\n",
        "\tmAP = mean(APs)\n",
        "\treturn mAP"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP9r5gfhzP8Q",
        "colab_type": "text"
      },
      "source": [
        "##Step 3: Train Neural Network on Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzbnNkFQtMGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RoadBikes_image_list=[] #creates a list with image name for Road Bikes\n",
        "for element in list(range(1,161)):\n",
        "  RoadBikes_image_list.append(str(element)+'.jpg')\n",
        "\n",
        "KidsBikes_image_list=[] #creates a list with image name for Kids Bikes\n",
        "for element in list(range(161,279)):\n",
        "  KidsBikes_image_list.append(str(element)+'.jpg')\n",
        "\n",
        "MTB_image_list=[] \n",
        "for element in list(range(279,439)):\n",
        "  MTB_image_list.append(str(element)+'.jpg')\n",
        "\n",
        "UrbanBikes_image_list=[] \n",
        "for element in list(range(439,525)):\n",
        "  UrbanBikes_image_list.append(str(element)+'.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZxzyjCZN1Qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %% prepare train set (make sure to import the model before doing so)\n",
        "train_set = BikesDataset()\n",
        "train_set.load_dataset(g_path+'Mask_RCNN/bikes/', is_train=True)\n",
        "train_set.prepare()\n",
        "print('Train: %d' % len(train_set.image_ids))\n",
        "# %% prepare train set (make sure to import the model before doing so)\n",
        "\n",
        "# prepare test/val set\n",
        "test_set = BikesDataset()\n",
        "test_set.load_dataset(g_path+'Mask_RCNN/bikes/', is_train=False)\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))\n",
        "# prepare config\n",
        "\n",
        "config = BikesConfig()\n",
        "config.display()\n",
        "# define the model\n",
        "model = MaskRCNN(mode='training', model_dir='./', config=config)\n",
        "# load weights (mscoco) and exclude the output layers\n",
        "model.load_weights('/content/drive/My Drive/Colab/mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "# train weights (output layers or 'heads')\n",
        "# model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=5, layers='heads')\n",
        "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=50, layers='heads') #training for longer to improve training set performance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cv-XKBrl3Z0",
        "colab_type": "text"
      },
      "source": [
        "##Step 4: Test on individual examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "metarPyTLEFN",
        "colab_type": "code",
        "outputId": "1c7c84f8-3fea-4934-ada2-b065dd4b3ced",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create model object in inference mode\n",
        "# model = modellib.MaskRCNN(mode='inference', model_dir=MODEL_DIR, config=config)\n",
        "model = modellib.MaskRCNN(mode='inference', model_dir=MODEL_DIR, config=PredictionConfig())\n",
        "\n",
        "\n",
        "#load weights\n",
        "# model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
        "# if choosing another model, make sure configurations match (especially number of classes)\n",
        "Model_Path ='/content/Mask_RCNN/bikes_cfg20200528T1628/mask_rcnn_bikes_cfg_0048.h5' #add model created here.\n",
        "model.load_weights(Model_Path, by_name=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Re-starting from epoch 48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hni0wxgXYKN",
        "colab_type": "text"
      },
      "source": [
        "###With training done, we proceed to test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlnQzHDEOOkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load a random image from the images folder\n",
        "file_names = next(os.walk(IMAGE_DIR))[2]\n",
        "# image = skimage.io.imread(os.path.join(IMAGE_DIR, random.choice(file_names)),plugin='matplotlib')\n",
        "image_list = RoadBikes_image_list+KidsBikes_image_list+MTB_image_list+UrbanBikes_image_list\n",
        "new_list =[]\n",
        "for image in image_list:\n",
        "  image = skimage.io.imread(os.path.join(IMAGE_DIR, image),plugin='matplotlib')\n",
        "  new_list.append(image)\n",
        "\n",
        "\n",
        "bike = 134\n",
        "for bike in list(range(400,440)):\n",
        "    \n",
        "  # Run detection\n",
        "  # \n",
        "  results = model.detect([new_list[bike]], verbose=1)\n",
        "\n",
        "  # Visualize results 0\n",
        "  r = results[0]\n",
        "  visualize.display_instances(new_list[bike], r['rois'], r['masks'], r['class_ids'], \n",
        "                              class_names, r['scores'])\n",
        "\n",
        "  #make sure to create check to see if the model detected something worth printing, and avoid traceback!\n",
        "  id = r['class_ids']\n",
        "\n",
        "  if not id.any():\n",
        "    print('predicted no object in image')\n",
        "  else:\n",
        "    print(class_names[id[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHkKpcQgfbvP",
        "colab_type": "text"
      },
      "source": [
        "###Code for further testing (to be added if necessary)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XglmnlgBzn1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # load the train dataset\n",
        "# train_set = BikesDataset()\n",
        "# train_set.load_dataset('/content/Mask_RCNN/bikes', is_train=True)\n",
        "# train_set.prepare()\n",
        "# print('Train: %d' % len(train_set.image_ids))\n",
        "# # load the test dataset\n",
        "# test_set = BikesDataset()\n",
        "# test_set.load_dataset('/content/Mask_RCNN/bikes', is_train=False)\n",
        "# test_set.prepare()\n",
        "# print('Test: %d' % len(test_set.image_ids))\n",
        "# # create config\n",
        "# cfg = PredictionConfig()\n",
        "# # define the model kangaroo\n",
        "# model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n",
        "# # load model weights\n",
        "# model_path = '/content/Mask_RCNN/bikes_cfg20200521T1953/mask_rcnn_bikes_cfg_0005.h5' # Change\n",
        "# model.load_weights(model_path, by_name=True)\n",
        "# # plot predictions for train dataset\n",
        "# plot_actual_vs_predicted(train_set, model, cfg)\n",
        "# # plot predictions for test dataset\n",
        "# plot_actual_vs_predicted(test_set, model, cfg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpynPw0c3xKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # load the train dataset\n",
        "# train_set = BikesDataset()\n",
        "# train_set.load_dataset('/content/Mask_RCNN/bikes', is_train=True)\n",
        "# train_set.prepare()\n",
        "# print('Train: %d' % len(train_set.image_ids))\n",
        "# # load the test dataset\n",
        "# test_set = BikesDataset()\n",
        "# test_set.load_dataset('/content/Mask_RCNN/bikes', is_train=False)\n",
        "# test_set.prepare()\n",
        "# print('Test: %d' % len(test_set.image_ids))\n",
        "# # create config\n",
        "# cfg = PredictionConfig()\n",
        "# # define the model\n",
        "# model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n",
        "# # load model weights\n",
        "# model.load_weights('/content/Mask_RCNN/bikes_cfg20200521T1953/mask_rcnn_bikes_cfg_0005.h5', by_name=True)\n",
        "# # evaluate model on training dataset\n",
        "# train_mAP = evaluate_model(train_set, model, cfg)\n",
        "# print(\"Train mAP: %.3f\" % train_mAP)\n",
        "# # evaluate model on test dataset\n",
        "# test_mAP = evaluate_model(test_set, model, cfg)\n",
        "# print(\"Test mAP: %.3f\" % test_mAP)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}